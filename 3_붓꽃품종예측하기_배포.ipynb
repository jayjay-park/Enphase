{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "3.붓꽃품종예측하기_배포.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park1125/Curating_Code/blob/master/3_%EB%B6%93%EA%BD%83%ED%92%88%EC%A2%85%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0_%EB%B0%B0%ED%8F%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-EEj2SG5bkr"
      },
      "source": [
        "# scikit-learn 설치\n",
        "# pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEMjeUWT5bk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63021085-6d1d-4868-97e5-77e9c60f3d9d"
      },
      "source": [
        "# scikit-learn import\n",
        "\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKFYizM65bk_"
      },
      "source": [
        "## Q1. 붓꽃 품종 예측하기\n",
        "- 붓꽃 데이터 셋트로 붓꽃의 품종을 분류(Classification)하기\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html?highlight=iris#sklearn.datasets.load_iris\n",
        "\n",
        "![img02-iris.png](http://drive.google.com/uc?export=view&id=1wRDNj7hsZH-niTbcYePPwSTsDKBqohYl)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nu2-_WK5blA"
      },
      "source": [
        "# sklearn.datasets : 사이킷런에서 제공하는 테스트 데이터셋의 모음\n",
        "# sklearn.tree : 트리 기반 ML 알고리즘을 구현한 클래스의 모음\n",
        "# sklearn.model_selection : \n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxS9cFmL5blF"
      },
      "source": [
        "#### step1. 붓꽃 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BocV783g5blG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f356a4-5f45-4371-e38a-61309d522e43"
      },
      "source": [
        "iris = load_iris()\n",
        "iris.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtYSpzMm5blL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017da670-662a-4b72-f156-ca1c94b6d64e"
      },
      "source": [
        "# data 살펴보기\n",
        "print(type(iris.data))\n",
        "\n",
        "iris_data = iris.data\n",
        "print(iris_data.shape)   # (150,4) ==> 4개의 열(feature)를 가진 150개 행\n",
        "print(iris_data[:5])\n",
        "print(iris.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(150, 4)\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tAVaCOw5blR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c0bebb-24ef-4d57-db72-bf692d6d4a73"
      },
      "source": [
        "# target 살펴보기\n",
        "# target, label, 레이블, 라벨, 정답 -> 몇 개의 class\n",
        "\n",
        "print(iris.target)\n",
        "\n",
        "iris_label = iris.target   # iris_label 에 copy\n",
        "print(iris_label.shape)    # (150,)\n",
        "print(iris.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "(150,)\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0har-zkrTQ15",
        "outputId": "c8a2e592-1cb7-43e1-9453-781c8b1b5bc1"
      },
      "source": [
        "# dataframe 으로 변환\n",
        "import pandas as pd\n",
        "\n",
        "# iris_data (4 col) + iris_label (1 col)\n",
        "df_iris = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "# df_iris['label'] 추가하겠습니다.\n",
        "df_iris['label'] = iris_label\n",
        "df_iris.head()\n",
        "\n",
        "df_iris[95:105]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>5.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>6.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>7.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
              "95                 5.7               3.0  ...               1.2      1\n",
              "96                 5.7               2.9  ...               1.3      1\n",
              "97                 6.2               2.9  ...               1.3      1\n",
              "98                 5.1               2.5  ...               1.1      1\n",
              "99                 5.7               2.8  ...               1.3      1\n",
              "100                6.3               3.3  ...               2.5      2\n",
              "101                5.8               2.7  ...               1.9      2\n",
              "102                7.1               3.0  ...               2.1      2\n",
              "103                6.3               2.9  ...               1.8      2\n",
              "104                6.5               3.0  ...               2.2      2\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT24vaxI5blX"
      },
      "source": [
        "#### step 2. 데이터세트 분리\n",
        "- 데이터를 학습(train) 데이터와 테스트(test) 데이터로 분리\n",
        "- train_test_split() : test_size=0.2 (테스트 20% = 30건 , 학습 80% = 120건 분할)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-dE2itC5blY"
      },
      "source": [
        "x_train, x_test, y_train, y_test  = train_test_split(iris_data, \n",
        "                                                     iris_label , \n",
        "                                                     test_size= 0.2, \n",
        "                                                     random_state=11 )\n",
        "\n",
        "# y =f(x)  x : feature들  , y : label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ60hkTDZi3A",
        "outputId": "791caa89-3c71-4869-c41c-90f5af6e3024"
      },
      "source": [
        "print(x_train.shape)    # (120 , 4 ) \n",
        "print(y_train.shape)    # (120 , )\n",
        "print(x_test.shape)     # (30 , 4)\n",
        "print(y_test.shape)     # (30  , )\n",
        "# train = 학습용,  test : 검증용"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(120,)\n",
            "(30, 4)\n",
            "(30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__N8r62oaJwa",
        "outputId": "307db0ee-6cbc-4ddd-b013-b1efa7c05a62"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 2, 0, 0, 2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 0, 2, 2,\n",
              "       1, 2, 1, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 2,\n",
              "       2, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 2,\n",
              "       1, 0, 0, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0,\n",
              "       2, 1, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 1, 2, 0, 2, 2, 0,\n",
              "       1, 2, 0, 1, 1, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu9m55Ix5bld"
      },
      "source": [
        "#### step 3. DecisionTreeClassifier 객체 생성\n",
        "- 모델을 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLs8LxWU5ble"
      },
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myOkRQEA5bli"
      },
      "source": [
        "#### step 4. 모델 학습\n",
        "- 학습데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-57YvW45blj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4e14e4-a1c7-46a3-e4e7-a9c3f6235905"
      },
      "source": [
        "dt_clf.fit( x_train , y_train )   # 지도학습 120건"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=11, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMZVlqBk5blm"
      },
      "source": [
        "#### step 5. 예측 수행\n",
        "- 학습된 ML모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측\n",
        "- 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nyxxVvJ5bln"
      },
      "source": [
        "pred = dt_clf.predict(x_test)   # 30건 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frVqyHBhbS7s",
        "outputId": "0aace2ad-2ca1-4d69-b371-9e354e6a8d69"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,\n",
              "       0, 1, 0, 0, 2, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gVhcl6KbSxQ",
        "outputId": "0eb8e2ee-1c2c-486b-b886-d2264ab148b5"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 1, 2, 0, 1, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,\n",
              "       0, 1, 0, 0, 2, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtP6WziYbp_U",
        "outputId": "5e31c6d3-cb2c-4f4c-f1d6-10fa6c646c26"
      },
      "source": [
        "# 30건 2개 오차 \n",
        "# accuracy =  맞춘건수 /전체건수\n",
        "28/30 \n",
        "# 0.9333333333333333"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2vNzgXO5blt"
      },
      "source": [
        "#### step 6. 평가\n",
        "- 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOvLx7td5blu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d1c659-fcd8-4276-def0-19b204024df5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN7OwYY95blx"
      },
      "source": [
        "## Q2. 사이킷런 프레임워크 익히기\n",
        "- Estimator 이해 및 fit(), predict() 메서드\n",
        "- 기본 Estimator 클래스 : 분류와 회귀로 나눔\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=19SSruDuzqIh2pICZiM9RhPbbvxoVXNTM\" width=\"600\">\n",
        "\n",
        "- 사이킷런의 주요 모듈 \n",
        "- https://scikit-learn.org/stable/modules/classes.html\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1KACaXAKgxwLw_QlbM7kh6kTuywJqzEbs\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9s7wsdb5bly"
      },
      "source": [
        "## Q3. 내장된 예제 데이터 세트 - 분류나 회귀용\n",
        "- 예제 데이터의 구성 \n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html?highlight=iris#sklearn.datasets.load_iris\n",
        "- 일반적으로 딕서너리 형태로 되어 있음\n",
        "- 키는 data, target, target_names, feature_names, DESCR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRB112fH5blz"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppaq7edi5bl2"
      },
      "source": [
        "# sklearn.utils.Bunch 는 파이썬의 딕셔너리와 비슷\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll_LeYx_5bmH"
      },
      "source": [
        "## Q4. Model Selection 모듈 소개\n",
        "- 데이터 세트 분리\n",
        "- 교차 검증 분할 및 평가\n",
        "- Estimator의 하이퍼 파라미터 튜닝을 위한 다양한 함수와 클래스 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crLWNJ6g5bmI"
      },
      "source": [
        "### 1) train/test 데이터 세트 분리 - train_test_split()\n",
        "- train/test 데이터 세트 분리 이유\n",
        "- test 데이터를 이용하기 않고 train 데이터 세트만으로 학습하고 예측해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kYjukEr5bmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57afbb4-f2b8-402f-d485-a84bead6275b"
      },
      "source": [
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "\n",
        "dt_clf.fit(train_data, train_label)  \n",
        "\n",
        "# 학습 데이터 세트로 예측 수행\n",
        "pred = dt_clf.predict(train_data)  \n",
        "print(accuracy_score(train_label, pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRK-mY8w5bmL"
      },
      "source": [
        "- train_test_split()\n",
        "- test_size : 전체 데이터에서 테스트 데이터 세트의 크기를 얼마로 샘플링할 것인가를 결정, default 0.25\n",
        "- train_size : 전체 데이터에서 학습용 데이터 세트의 크기를 얼마로 샘플링할 것인가를 결정, 통상적으로 test_size 사용\n",
        "- shuffle : 데이타를 분리하기 전에 미리 섞을지를 결정, default True\n",
        "- random_state : 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 train/test 데이터세트를 생성, \n",
        "random값을 만드는 seed와 같은 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx_NSDH15bmP"
      },
      "source": [
        "### 2) 교차 검증\n",
        "- KFold, Stratified KFold, cross_val_score() \n",
        "- Overfitting : 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 의미\n",
        "- 본고사 치르지 건에 모의고사를 여러번 보는 것과 같음\n",
        "- 학습 데이터를 다시 분할하여 학습 데이터와 학습된 모델의 성능을 일차 평가하는 검증 데이터로 나눔\n",
        "- 검증 데이터세트로 1차 평가를 한 뒤에 최종적으로 테스트 데이터세트에 적용해 평가하는 프로세스\n",
        "- train/validation/test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gek5MfbI5bmQ"
      },
      "source": [
        "#### 2-1) K 폴드 교차 검증\n",
        "- K 개의 폴드를 만들어서 진행하는 교차검증\n",
        "\n",
        "[과정]\n",
        "\n",
        "- Training set과 Test set을 나눈다\n",
        "- Training set을 K개의 fold로 나눈다 \n",
        "- 한 개의 fold에 있는 데이터를 다시 K개로 쪼갠 다음, K-1개는 Training data, 마지막 한개는 Validation data로 지정한다\n",
        "- Training data로 학습을 수행하고 Validation data로 평가를 수행한다 \n",
        "- 두번째 반복에서 Training data와 Validation data를 변경하여 같은 방식으로 학습과 평가 작업을 수행한다\n",
        "- 이런식으로 데이터 셋을 점진적으로 변경하면서 K번째까기 학슴과 검증을 수행한다\n",
        "- K개의 예측 평가를 구했으면 이를 평균해서 K폴드 평가 결과로 반영한다\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1JDNpCIDhJdw7slx5fCY12Q827jaKHDnE\" width=\"600\">\n",
        "\n",
        "[사용이유]\n",
        "\n",
        "- 총 데이터 개수가 적은 데이터 세트에 대해 정확도를 향상시킬 수 있음\n",
        "- 이는 train/validation/test dataset으로 분류하는 것이 training과 test로만 분류할 때보다 학습 데이터셋이 더 많기 때문\n",
        "- 데이터 수가 적으면 과소적합\n",
        "\n",
        "\n",
        "\n",
        "- K폴드 교차 검증 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhwUlHc5bmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a5ff4a-dff6-4ceb-fe28-3d291bc3c3b6"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split , KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# iris load\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "\n",
        "# train_test_split  생략  전체 150건\n",
        "# classifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# kfold 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []   # cv = cross validtaion \n",
        "\n",
        "for train_index , test_index in kfold.split(features) : # k 갯수만큼 for문 반복\n",
        "    # train, test 셋 만들고\n",
        "    x_train = features[train_index]\n",
        "    x_test  = features[test_index] \n",
        "    y_train = label[train_index]\n",
        "    y_test  = label[test_index]\n",
        "\n",
        "    # fit, predict , score -> list 담기 \n",
        "    dt_clf.fit(x_train, y_train)\n",
        "    pred = dt_clf.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "from sklearn.metrics import accuracy_score <- 위에 이거 추가해주세요\n",
        "import numpy as np <- 위에 추가해주세요\n",
        "# list에 있는 accuracy를 평균\n",
        "print(cv_accuracy)   # 5개\n",
        "print(np.mean(cv_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 0.9666666666666667, 0.8666666666666667, 0.9333333333333333, 0.7333333333333333]\n",
            "0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yACL66id5bmT"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ZBhzEm5bmW"
      },
      "source": [
        "- K폴드 교차검증의 함정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Drj-sLN5bmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc057c1-3c09-4758-ecdb-cfa27dcbc2c7"
      },
      "source": [
        "print(test_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8UKLnJlGTMd",
        "outputId": "d6fa55a2-6e2e-47ad-f9d7-45a33a43d4bd"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBhRh6QQ5bmc"
      },
      "source": [
        "#### 2-2) Stratified K 폴드 \n",
        "- 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 분배하는 방식\n",
        "- 왜곡된 레이블 데이터 세트에서는 반드시 Stratified K폴드를 이용해 교차 검증을 해야함\n",
        "- 분류에서의 교차 검증은 Stratified K폴드로 분할\n",
        "- 회귀에서는 Stratified K폴드 지원하지 않음 ( 회귀의 결정값은 이산값이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 게 의미없음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VfDs2_y5bmc",
        "outputId": "547a5421-3dfc-4fe8-c05c-7388d43f6056"
      },
      "source": [
        "# Stratified K 폴드 구현\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1번째 교차검증 정확도 : 0.9667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
            "1번째 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
            "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "2번째 교차검증 정확도 : 0.9667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
            "2번째 검증 세트 인덱스 : [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
            "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "3번째 교차검증 정확도 : 0.9, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
            "3번째 검증 세트 인덱스 : [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
            "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
            "\n",
            "4번째 교차검증 정확도 : 0.9667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
            "4번째 검증 세트 인덱스 : [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
            "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
            "\n",
            "5번째 교차검증 정확도 : 1.0, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
            "5번째 검증 세트 인덱스 : [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
            "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "교차 검증별 정확도 : [0.9667 0.9667 0.9    0.9667 1.    ]\n",
            "평균 검증 정확도 : 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMb1WM5k5bmf"
      },
      "source": [
        "#### 2-3) 교차 검증을 보다 간편하게 - cross_val_score()\n",
        "- 교차 검증을 위한 API 제공\n",
        "- 일련의 과정을 한꺼번에 수행해주는 API - cross_val_score()\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
        "- cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
        "- estimator : 분류 알고리즘 클래스\n",
        "- X : 피처 데이터 세트\n",
        "- y : 레이블 데이터 세트\n",
        "- scoring : 예측 성능 평가 지표 ( 예. scoring='accuracy' )\n",
        "- cv : 교차 검증 플드 수\n",
        "- 반환값 : 성능 지표 측정값을 배열 형태로 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCVw0fLt5bmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef07de4-b892-487b-ce6e-ab27c1daa0c3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# load\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "\n",
        "# dt_clf 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=10)\n",
        "\n",
        "# kfold-> for 문 (fit predict score)  ==> cross_val_score\n",
        "scores = cross_val_score ( dt_clf, features, label, scoring='accuracy', cv=5)\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
            "0.9533333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH3EMo2y5bml"
      },
      "source": [
        "### 3) GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
        "- 하이퍼 파라미터란? 모델에서 외적인 요소 즉 데이터 분석을 통해 얻어지는 값이 아님\n",
        "- GridSearchCV API는 분류나 회귀와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하며서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공 (Grid란 격자라는 뜻으로 촘촘하게 파라미터를 입력하면서 테스트를 하는 방식)\n",
        "\n",
        "\n",
        "[ 하이퍼 파라미터 특징 ]\n",
        "\n",
        "- 모델 파라미터 값을 측정하기 위해 알고리즘 구현 과정에서 사용된다\n",
        "- 주로 알고리즘 사용자에 의해 결정된다\n",
        "- 경험에 의해 정해지기도 한다. 즉 알고리즘을 여러 번 수행해보면서 최적의 값을 직감적으로 알게된다\n",
        "- 예측 알고리즘 모델링의 문제점을 위해 조절된다\n",
        "- 예) 딥러닝에서 learning rate, 분류에서 max_depth, KNN에서 K의 개수\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1-p78-r5bml"
      },
      "source": [
        "# import \n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # 추가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load \n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_label = iris.target\n",
        "\n",
        "# train_test_split \n",
        "x_train, x_test, y_train, y_test  = train_test_split(iris_data, \n",
        "                                                     iris_label , \n",
        "                                                     test_size= 0.2, \n",
        "                                                     random_state=11 )\n",
        "\n",
        "# dt_clf 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# parameter 만들고 ~\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}  # 6개 case \n",
        "grid_tree = GridSearchCV(dt_clf, param_grid=parameters, cv=3, refit=True) # 6*cv = 18번\n",
        "grid_tree.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96yfN93BOcs7"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(grid_tree.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "mUu0Z79yPegx",
        "outputId": "d30904e2-90f7-4335-b10c-d818a3a7f0f9"
      },
      "source": [
        "df[['params','mean_test_score','rank_test_score' ]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  mean_test_score  rank_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}         0.675000                5\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}         0.675000                5\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}         0.966667                1\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}         0.966667                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEc7iwxBQxfk",
        "outputId": "4eaa8b0a-4ee6-4797-80df-d4a054cce503"
      },
      "source": [
        "grid_tree.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 3, 'min_samples_split': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N29I4zmrQxjx",
        "outputId": "72de4374-bb80-4b2d-a409-102854bc0adb"
      },
      "source": [
        "grid_tree.best_score_   # 3% train data에 과대적합 최적화"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jqIn10kQxWP",
        "outputId": "206201d3-cfdc-4b72-bdbf-8a2af49d0688"
      },
      "source": [
        "est = grid_tree.best_estimator_   # \n",
        "pred = est.predict(x_test)\n",
        "accuracy_score(y_test, pred)   # 일반화 모델 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WatSleaN5bmy"
      },
      "source": [
        "## Q5. 데이터 전처리\n",
        "- Garbage In, Garbage Out\n",
        "- 결손값(NaN, Null) : 허용 안됨, 고정된 다른 값으로 변환, 대부분이라면 삭제, 중요도가 높은 피처의 경우 정밀한 대체 값을 선정.\n",
        "- 문자열 값: 허용 안됨. 숫자형으로 변환. 카테고리형 피쳐는 코드 값으로, 텍스트형 피처는 피처 백터화, 불필요한 피처는 삭제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvq44bMz5bmy"
      },
      "source": [
        "### 1) 데이터 인코딩\n",
        "- 인코딩이란 ? 정보의 형태나 형식을 변환하는 처리나 처리 방식, 부호화\n",
        "- 인코딩 방식 : 레이블 인코딩 ( label encoding ), 원-핫 인코딩 (One Hot encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-CHvBN55bm2"
      },
      "source": [
        "#### 1-1 레이블 인코딩\n",
        "- 카테고리 피처를 코드형 숫자 값으로 변환하는 것\n",
        "- LabelEncoder 클래스로 구현\n",
        "- LabelEncoder 객체 생성 후 fit(), transform() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgsDQbmZ5bm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c489809c-8a13-4cbf-fc44-0d27fbaa16d8"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '컴퓨터', '믹서', '컴퓨터', '선풍기']\n",
        "\n",
        "# 객체생성 -> fit -> transform\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)   # 기준정보 설정, 학습 x\n",
        "labels = encoder.transform(items)  # 변환\n",
        "\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 4 2 4 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDa5ROK15bm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19663ba8-1bb9-456e-c5b2-968f6808f0c0"
      },
      "source": [
        "# 숫자값에 대한 class 이름 정보\n",
        "encoder.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['TV', '냉장고', '믹서', '선풍기', '컴퓨터'], dtype='<U3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihlyMxN15bm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a7cfc5-201a-4a7b-e30b-066dbfdc9371"
      },
      "source": [
        "# 디코딩\n",
        "encoder.inverse_transform([3,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['선풍기', '컴퓨터'], dtype='<U3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5HADrmM5bnB"
      },
      "source": [
        "#### 1-2 원-핫 인코딩 (One-Hot Encoding)\n",
        "- label encoding이 일괄적인 숫자 값으로 변환하는데 숫자 값의 크고 작음에 대한 특성이 작용해 예측 성능이 떨어지는 경우 발생\n",
        "- 1보다 2가 더 큰 값이므로 특정 ML 알고리즘에서 가중치가 더 부여되거나 더 중요하게 인식할 가능성 발생\n",
        "- 따라서 레이블 인코딩은 선형회귀에서는 적용 X, 트리 계열 알고리즘은 숫자의 이러한 특성을 반영하지 않음\n",
        "- 이 문제점을 해결하기 위해 원-핫 인코딩 방식 \n",
        "- 원-핫 인코딩 : \n",
        "- OneHotEncoder 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaoq71j05bnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d760efea-d7c2-4c97-caf6-c574715c8739"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '컴퓨터', '믹서', '컴퓨터', '선풍기']\n",
        "\n",
        "# label encoding 객체생성 -> fit -> transform\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)   # 기준정보 설정, 학습 x\n",
        "labels = encoder.transform(items)  # 변환\n",
        "\n",
        "labels = labels.reshape(-1,1)  # 2D로 변환\n",
        "\n",
        "# one hot encoding 객체생성 -> fit -> transform\n",
        "ohencoder = OneHotEncoder()\n",
        "ohencoder.fit(labels)   # 2D \n",
        "ohlabels = ohencoder.transform(labels)\n",
        "\n",
        "print(type(ohlabels))\n",
        "print(ohlabels.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdhdWqpaidh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Km4Cs15bnE"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DuVO_Sx5bnH"
      },
      "source": [
        "### 2) 피처 스케일링과 정규화\n",
        "- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 피처 스케일링이라고 합니다\n",
        "- 예. 달러와 원화를 비교하기 위해 가격의 단위를 조정 \n",
        "- 대표적인 방법으로 표준화(StandardScaler) 와 정규화(Normalization)이 있습니다\n",
        "- 데이터 특징에 따라서 선택"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr-QUIsc5bnI"
      },
      "source": [
        "#### 2-1 표준화 - StandardScaler\n",
        "- 표준화는 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것을 의미\n",
        "- 표준화를 쉽게 지원하는 클래스 StandardScaler\n",
        "- SVM, 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 됩니다\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1si8GD9t3rsMmKEBzDmp2wTBM9vkcVSAa\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rEmDBccr5bnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2b8639-78a2-4c3f-ef1f-c71d1da7e2b9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print (\"****************\")\n",
        "print (iris_df.mean())\n",
        "print (iris_df.var())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(iris_df)\n",
        "t_scaler = scaler.transform(iris_df)\n",
        "print(iris_df.shape)\n",
        "\n",
        "iris_df = pd.DataFrame(data=t_scaler, columns=iris.feature_names) \n",
        "print (\"****************\")\n",
        "print (iris_df.mean())\n",
        "print (iris_df.var())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n",
            "(150, 4)\n",
            "****************\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWR02mCP5bnM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW6fg20Z5bnX"
      },
      "source": [
        "#### 2-2 MinMaxScaler\n",
        "- 정규화란 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것\n",
        "- 데이터 값을 0과 1사이의 범위 값으로 변환\n",
        "- 정규화를 지원하는 클래스 MinMaxScaler\n",
        "- 데이터 분포가 가우시안 분포가 아닐 경우 적용해 볼 수 있음\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1ON54xIjh7-iALWJXd-HIhHzq611_E5Jo\" width=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq1vE0oj5bnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a23ea0c-deb9-406f-a17a-1729b40b119e"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print(iris_df_scaled.min())\n",
        "print(iris_df_scaled.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6KTdukz5bne"
      },
      "source": [
        "#### 2-3 스케일링 변환 시 유의점\n",
        "- fit(), transform(), fit_transform()\n",
        "- fit()은 데이터 변환을 위한 기준 정보 설정 (예를 들어 데이터세트의 최댓값/최솟값 설정)\n",
        "- transform() 은 이 정보를 이용해 데이터를 변환\n",
        "- 주의점. 학습 데이터로 fit()이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야함. \n",
        "- 즉, Scaler 객체를 이용해 학습 데이터 세트로 fit()과 transform()을 적용하면 테스트 데이터로는 다시 fit()을 수행하지 않고 fit()한 결과를 이용해 transform()변환을 적용해야 함 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO4secxj5bnu"
      },
      "source": [
        "[스케일링 변환 시 유의 점 요약]\n",
        "\n",
        "1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
        "2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환"
      ]
    }
  ]
}
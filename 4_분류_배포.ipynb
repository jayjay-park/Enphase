{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "4.분류_배포.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park1125/LibraryForLearning/blob/master/4_%EB%B6%84%EB%A5%98_%EB%B0%B0%ED%8F%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMUTT-l1QOZS"
      },
      "source": [
        "## 분류 ( Classification )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeSVddfOQOZU"
      },
      "source": [
        "- 지도학습은 레이블(label)이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식\n",
        "- 지도학습의 대표적인 유형인 분류는 주어진 피처와 레이블(결정값, 클래스값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고\n",
        "- 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측하는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1_mVr_BQOZU"
      },
      "source": [
        "## 1. 결정 트리 (Decision Tree)\n",
        "- 직관적으로 이해하기 쉬운 알고리즘\n",
        "- 데이터에 있는 규칙을 학습을 통해 트리 기반의 분류 규칙을 생성\n",
        "\n",
        "### 결정 트리 구조\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1GML_hlmhRn2luwZfhb45QZ5UAdnRat8k\" width=\"500\"  >\n",
        "\n",
        "- 데이터와 규칙이 복잡할 수록 Decision Node가 많이 생김 ( depth 증가, 과적합 가능성 )\n",
        "\n",
        "### 결정 노드 규칙\n",
        "- 가능한 적은 결정 노드로 높은 예측 정확도 목표\n",
        "- 결정노드는 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만듦\n",
        "- DecisionTreeClassifier는 기본으로 지니 계수를 이용해 분할\n",
        "\n",
        "### 결정 트리 장.단점\n",
        "- 장점 : 쉽고 직관적, 피처의 스케일링이나 정규화 등의 사전 가공 영향도가 크지 않음\n",
        "- 단점 : 과적합으로 알고리즘 성능 저하, 튜닝 필요\n",
        "\n",
        "### 결정 트리 파라미터\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "\n",
        "### 결정 트리 모델의 시각화\n",
        "- Graphviz 패키지 ( https://www.graphviz.org )\n",
        "- 사이킷런의 export_graphviz() API를 이용하여 인터페이스\n",
        "- 윈도우 버전의 Graphviz를 설치 ( C/C++ )  -> 파이썬 래퍼 모듈 설치 (pip install graphviz) -> 환경변수 path 설정\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1qPPJdOgEu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaVA0wrhOgZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGhjxuS7OgWh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5AXyLxxOgBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgFSaSuIQOZj"
      },
      "source": [
        "- DecisionTreeClassifier 객체의 feature_importances_ 속성 \n",
        "- 피처의 중요한 역할 지표, ndarray 형태로 피처 순서대로 값을 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67oZvFS3OibI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5P5U-A7OiXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHAtAx3zQOZo"
      },
      "source": [
        "### 결정 트리 과적합 (Overfitting)\n",
        "- 과적합 문제를 시각화\n",
        "- 분류를 위한 테스트 세트 만들기\n",
        "- make_classification() 함수 제공\n",
        "- 2개의 피처가 3가지 유형의 클래스 값을 가지는 데이터 세트 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vDzwMLaOnsY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOhyMjUPQOZt"
      },
      "source": [
        "## 2. 앙상블 학습\n",
        "- 여러 개의 분류기의 예측을 결합하여 신뢰성이 높은 예측값을 얻는 것\n",
        "- 랜덤 포레스트, 그래디언트 부스팅 알고리즘이 많이 애용\n",
        "- 앙상블 학습의 유형 : 보팅(Voting), 배깅(Bagging), 부스팅(Boosting)\n",
        "\n",
        "\n",
        "### 보팅 유형 - Hard Voting, Soft Voting\n",
        "- Hard Voting : 다수의 classifier간 다수결로 최종 class 결정\n",
        "- Soft Voting : 다수의 classifier들의 class확률을 평균하여 결정\n",
        "\n",
        "### 보팅 분류기 ( Voting Classifier )\n",
        "- VotingClassifier 클래스 제공\n",
        "- 위스콘신 대학교에서 제공한 유방암 진단결과 데이터로 유방암 예측 분류를 해봅시다\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
        "- 레코드 수 569개, 30개의 실측값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwc4Y-OJOsmz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFdMVq2gOscm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JoSeLzNOsb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c4qCExoQOZ5"
      },
      "source": [
        "- 과적합이 생기기 쉬운 결정 트리 알고리즘의 경우 단점을 보완하기 위해 수십~수천 개의 매우 많은 분류기를 결합해 다양한 상황을 학습하게 함으로써 극복"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUtHktojQOZ6"
      },
      "source": [
        "## 3. RandomForest \n",
        "- 배깅의 대표적인 알고리즘 ( 같은 알고리즘으로 여러 개의 분류기 학습 )\n",
        "- 비교적 빠른 속도, 다양한 영역에서 높은 예측 성능\n",
        "- 기반 알고리즘은 결정 트리로서 결정 트리의 쉽고 직관적인 장점을 그대로 가지고 있음\n",
        "\n",
        "\n",
        "\n",
        "### bootstrapping\n",
        "- 여러 개의 데이터 세트를 중첩되게 분리하는 것\n",
        "- 통계학에서 여러 개의 작은 데이터 세트를 임의로 만들어 개별 평균의 분포도를 측정하는 등의 목적의 샘플링 방식\n",
        "\n",
        "\n",
        "### 실습\n",
        "- RandomForest를 이용해 위스콘신 대학교에서 제공한 유방암 진단결과 데이터로 유방암 예측 분류를 해봅시다\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
        "- 레코드 수 569개, 30개의 실측값\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfCWIq7FOuzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apzKyA9mOuq4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rsS_p6EQOaD"
      },
      "source": [
        "### RandomForest 하이퍼 파라미터 및 튜닝\n",
        "- n_estimator: Random Forest 에서 사용할 Decision Tree 모델의 개수\n",
        "- max_features : 최적의 분할ㅇ을 위해 고려해야 할 최대 feature 수, default 값은 ,'auto' 즉 'sqrt'\n",
        "- max_depth, min_samples_leaf는 결정트리와 같음\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK6kNWMXOx07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lcahS0TOx4f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liAPvM4hOxx6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33DEAVM3QOaK"
      },
      "source": [
        "## 4. GBM (Gradient Boosting Machine)\n",
        "- 여러 개의 약한 학습기를 순차적으로 학습-예측하면서\n",
        "- 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식\n",
        "- 대표적인 구현 : AdaBoost (Adaptiv boosting),  그래디언트 부스트\n",
        "- AdaBoost의 학습 과정\n",
        "\n",
        "\n",
        "### GBM\n",
        "- 에이다부스트와 유사하나, 가중치 업데이트를 경사하강법(Gradient Descent)을 이용\n",
        "- 오류 값 = 실제값 - 예측값, 오류값을 최소화하는 방향성을 가지고 반복적으로 가중치 값을 업데이트\n",
        "- GBM은 CART( Classification And Regression Trees ) 기반, 즉 분류,회귀 가능\n",
        "- GradientBoostClassifier 클래스 제공\n",
        "\n",
        "### 실습\n",
        "- GBM을 이용해 위스콘신 대학교에서 제공한 유방암 진단결과 데이터로 유방암 예측 분류를 해봅시다\n",
        "- 학습하는 수행 시간도 같이 측정해봅시다\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOn2cabRb7i5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjlnUkOGb7VQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH57pNN_QOaS"
      },
      "source": [
        "- 기본 하이퍼 파라미터만으로도 랜덤 포레스트보다 나은 예측 성능 ( 일반적 )\n",
        "- but 수행 시간이 오래 걸리고, 하이퍼 파라미터 튜닝 필요, 수행 시간 오래 걸림 ( 순차적 예측 오류 보정 - 병렬 처리 X, 랜덤포레스트 - 병렬)\n",
        "\n",
        "### GBM 하이퍼 파라미터 및 튜닝\n",
        "- max_depth, max_features 등 트리 기반 파라미터는 동일\n",
        "- n_estimators : weak learner 의 개수, 순차적 오류 보정으로 개수가 많을 수록 예측 성능 좋아짐, 수행시간 오래 걸림. default = 100\n",
        "- loss : 경사 하강법에서 사용할 비용 함수. default = 'deviance' \n",
        "- learning_rate : 학습률, 순차적 오류 값을 보정할 때 적용하는 계수. 0~1사이 값. 기본값 = 0.1, 너무 작으면 업데이트되는 값이 작아짐\n",
        "- subsample : weak learner가 학습에 사용하는 데이터의 샘플링 비율, 기본 값 1이며 전체 학습 데이터를 기반으로 학습. 과적합을 줄이기 위해 1보다 작은 값을 설정\n",
        "\n",
        "###  실습 \n",
        "- GridSearchCV를 이용해 하이퍼 파라미터를 최적화해봅시다\n",
        "- n_estimators 100, 500,  learning_rate = 0.05, 0.1 로 제약"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DvBf32Db-1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-NqAfUHb-yZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}